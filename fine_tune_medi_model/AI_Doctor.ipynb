{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e116cd2c0f664dac82e0d6a07523d2fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9afb3921056e489581b4540289e8ae37",
              "IPY_MODEL_7491848e0e1c4afe94cd5ca343f45be5",
              "IPY_MODEL_c74314cdd42f4d02b061208d025ad349"
            ],
            "layout": "IPY_MODEL_7a02f2eba726460485026d7c9b7699be"
          }
        },
        "9afb3921056e489581b4540289e8ae37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48d5430ef5d34dbc8d56fc7735f5c5f8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8d3d2d92bcbe466487fc1ecb755c1783",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá100%"
          }
        },
        "7491848e0e1c4afe94cd5ca343f45be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b8ee95a91a24bd5947c0ccd73e406f3",
            "max": 19704,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3134d3ada6b94783af670a1956f3e243",
            "value": 19704
          }
        },
        "c74314cdd42f4d02b061208d025ad349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_003a3cdd0b5d47d9a299776db72f5937",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_402c344a6dd4498fa4181f504d83cfa0",
            "value": "‚Äá19704/19704‚Äá[00:01&lt;00:00,‚Äá14354.34‚Äáexamples/s]"
          }
        },
        "7a02f2eba726460485026d7c9b7699be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48d5430ef5d34dbc8d56fc7735f5c5f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d3d2d92bcbe466487fc1ecb755c1783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b8ee95a91a24bd5947c0ccd73e406f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3134d3ada6b94783af670a1956f3e243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "003a3cdd0b5d47d9a299776db72f5937": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "402c344a6dd4498fa4181f504d83cfa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33977379baec4807b9caf39508979a1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72c34160ae3f460095a21b5f0068e8a3",
              "IPY_MODEL_a3b45ff39d16465b8e88d4259070b518",
              "IPY_MODEL_b4bdb99c498c44e6986f1dade6486216"
            ],
            "layout": "IPY_MODEL_0cac67badfed4bb6952d3e3fe7e26e82"
          }
        },
        "72c34160ae3f460095a21b5f0068e8a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2d0ac22a5e145acabb52b657fb6e580",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0f45bc0a53714588bf6868e829c68982",
            "value": "Unsloth:‚ÄáTokenizing‚Äá[&quot;text&quot;]‚Äá(num_proc=4):‚Äá100%"
          }
        },
        "a3b45ff39d16465b8e88d4259070b518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_033d2fc08cd449219e4fcaad4a5dfd41",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91d910431eee441bac359cb550036d52",
            "value": 500
          }
        },
        "b4bdb99c498c44e6986f1dade6486216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3eb7342a87842b385b1e35d78a199f7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a4a69782a79241509ad8563e5816fd8d",
            "value": "‚Äá500/500‚Äá[00:04&lt;00:00,‚Äá144.82‚Äáexamples/s]"
          }
        },
        "0cac67badfed4bb6952d3e3fe7e26e82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2d0ac22a5e145acabb52b657fb6e580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f45bc0a53714588bf6868e829c68982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "033d2fc08cd449219e4fcaad4a5dfd41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91d910431eee441bac359cb550036d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3eb7342a87842b385b1e35d78a199f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4a69782a79241509ad8563e5816fd8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install unsloth\n",
        "!pip install --force-reinstall --no-cache-dir git+https://github.com/unslothai/unsloth.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WsX1n2PBEuz",
        "outputId": "beeffe0c-f9fe-4aa2-f9a0-ecffdbf22f94"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unsloth in /usr/local/lib/python3.12/dist-packages (2026.1.4)\n",
            "Collecting git+https://github.com/unslothai/unsloth.git\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-req-build-0lrhxwj6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-req-build-0lrhxwj6\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit 485be2a33e52b83bb4bbf45743f74e853ef038da\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: unsloth\n",
            "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unsloth: filename=unsloth-2026.1.4-py3-none-any.whl size=412749 sha256=36103900def72da886c85b6911c8fa3a010ff9d3458c601d2794731391c98618\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fhc96guj/wheels/60/3e/1f/e576c07051d90cf64b6a41434d87ccf4db33fafd5343bf5de0\n",
            "Successfully built unsloth\n",
            "Installing collected packages: unsloth\n",
            "  Attempting uninstall: unsloth\n",
            "    Found existing installation: unsloth 2026.1.4\n",
            "    Uninstalling unsloth-2026.1.4:\n",
            "      Successfully uninstalled unsloth-2026.1.4\n",
            "Successfully installed unsloth-2026.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6PcPMr8LCgia"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8pmYOobvDhDk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pXZpnRicD0EO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oKhnnZ7YDnnX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6vHj8xfGD5Qz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tUdPuOxZEEvS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from trl import SFTTrainer\n",
        "from unsloth import is_bfloat16_supported\n",
        "from huggingface_hub import login\n",
        "from transformers import TrainingArguments\n",
        "from datasets import load_dataset\n",
        "import wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww-PIUjxEm0v",
        "outputId": "7f57d362-a25c-4e5b-95fd-4bf34e72de2f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token)"
      ],
      "metadata": {
        "id": "tTm2iAEdE11Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"GPU device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7oAYEvMOVZR",
        "outputId": "93314e38-8bed-4fc1-89b9-2066755f0cd1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU device: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
        "max_sequence_length = 2048\n",
        "dtype = None #model check data type at run time (that is int num char or other)\n",
        "load_in_4bit = True\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_name,\n",
        "    max_seq_length = max_sequence_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    token = hf_token\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd4VJ8ZgSDKb",
        "outputId": "5756f07f-051d-490e-9b01-0c66f424271f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2026.1.4: Fast Llama patching. Transformers: 4.57.6.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.6.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.34. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d71a6ca9",
        "outputId": "bd89a39a-9b3b-4393-8031-066d038b0987"
      },
      "source": [
        "pip install modelscope"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting modelscope\n",
            "  Downloading modelscope-1.34.0-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from modelscope) (3.20.3)\n",
            "Requirement already satisfied: requests>=2.25 in /usr/local/lib/python3.12/dist-packages (from modelscope) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from modelscope) (75.2.0)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.12/dist-packages (from modelscope) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.12/dist-packages (from modelscope) (2.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25->modelscope) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25->modelscope) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25->modelscope) (2026.1.4)\n",
            "Downloading modelscope-1.34.0-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: modelscope\n",
            "Successfully installed modelscope-1.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e95dc6f6",
        "outputId": "eee61288-58ae-43b5-f866-de19198ebe5a"
      },
      "source": [
        "import os\n",
        "os.environ['UNSLOTH_USE_MODELSCOPE'] = '1'\n",
        "print('UNSLOTH_USE_MODELSCOPE environment variable set to 1.')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNSLOTH_USE_MODELSCOPE environment variable set to 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbb69c6f",
        "outputId": "57df62e5-175f-45c8-da75-364e58ea40be"
      },
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
        "max_sequence_length = 2048\n",
        "dtype = None #model check data type at run time (that is int num char or other)\n",
        "load_in_4bit = True\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_name,\n",
        "    max_seq_length = max_sequence_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    token = hf_token\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2026.1.4: Fast Llama patching. Transformers: 4.57.6.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.6.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.34. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_style = \"\"\"\n",
        "Below is a task description along with additional context provided in the input section. Your goal is to provide a well-reasoned response that effectively addresses the request.\n",
        "\n",
        "Before crafting your answer, take a moment to carefully analyze the question. Develop a clear, step-by-step thought process to ensure your response is both logical and accurate.\n",
        "\n",
        "### Task:\n",
        "You are a medical expert specializing in clinical reasoning, diagnostics, and treatment planning. Answer the medical question below using your advanced knowledge.\n",
        "\n",
        "### Query:\n",
        "{}\n",
        "\n",
        "### Answer:\n",
        "{}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rMI_Y1YySdm6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a test question\n",
        "question = \"\"\"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or\n",
        "              sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings,\n",
        "              what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\"\"\n",
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate a response\n",
        "outputs = model.generate (\n",
        "    input_ids = inputs.input_ids,\n",
        "    attention_mask = inputs.attention_mask,\n",
        "    max_new_tokens = 1200,\n",
        "    use_cache = True\n",
        ")\n",
        "\n",
        "# Decode the response tokens back to text\n",
        "response = tokenizer.batch_decode(outputs)\n",
        "\n",
        "\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gjye1HBNTeAw",
        "outputId": "523ba147-6281-4e4c-880f-f8950a4858a9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<ÔΩúbegin‚ñÅof‚ñÅsentenceÔΩú>\\nBelow is a task description along with additional context provided in the input section. Your goal is to provide a well-reasoned response that effectively addresses the request.\\n\\nBefore crafting your answer, take a moment to carefully analyze the question. Develop a clear, step-by-step thought process to ensure your response is both logical and accurate.\\n\\n### Task:\\nYou are a medical expert specializing in clinical reasoning, diagnostics, and treatment planning. Answer the medical question below using your advanced knowledge.\\n\\n### Query:\\nA 61-year-old woman with a long history of involuntary urine loss during activities like coughing or\\n              sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings,\\n              what would cystometry most likely reveal about her residual volume and detrusor contractions?\\n\\n### Answer:\\n\\nThe cystometry would most likely reveal that the residual volume is normal and there are no detrusor contractions. This is because the patient does not experience urine leakage at night, which suggests that her bladder is functioning properly when it is not under stress. Additionally, since she has a long history of involuntary urine loss during activities like coughing or sneezing, the Q-tip test, which assesses for urethral obstruction, would likely be negative. Therefore, the findings point towards normal residual volume and normal detrusor contractions.\\n</think>\\n\\n**Answer:**\\n\\nThe cystometry would most likely reveal that the residual volume is normal and there are no detrusor contractions. This is because the patient does not experience urine leakage at night, which suggests that her bladder is functioning properly when it is not under stress. Additionally, since she has a long history of involuntary urine loss during activities like coughing or sneezing, the Q-tip test, which assesses for urethral obstruction, would likely be negative. Therefore, the findings point towards normal residual volume and normal detrusor contractions.<ÔΩúend‚ñÅof‚ñÅsentenceÔΩú>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "medical_dataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\", \"en\", split = \"train[:500]\", trust_remote_code = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "e116cd2c0f664dac82e0d6a07523d2fb",
            "9afb3921056e489581b4540289e8ae37",
            "7491848e0e1c4afe94cd5ca343f45be5",
            "c74314cdd42f4d02b061208d025ad349",
            "7a02f2eba726460485026d7c9b7699be",
            "48d5430ef5d34dbc8d56fc7735f5c5f8",
            "8d3d2d92bcbe466487fc1ecb755c1783",
            "1b8ee95a91a24bd5947c0ccd73e406f3",
            "3134d3ada6b94783af670a1956f3e243",
            "003a3cdd0b5d47d9a299776db72f5937",
            "402c344a6dd4498fa4181f504d83cfa0"
          ]
        },
        "id": "ykBsouSdUpQn",
        "outputId": "79a5c1fa-7926-4e38-c7f6-e1b901cc82d8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`trust_remote_code` is not supported anymore.\n",
            "Please check that the Hugging Face dataset 'FreedomIntelligence/medical-o1-reasoning-SFT' isn't based on a loading script and remove `trust_remote_code`.\n",
            "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n",
            "ERROR:datasets.load:`trust_remote_code` is not supported anymore.\n",
            "Please check that the Hugging Face dataset 'FreedomIntelligence/medical-o1-reasoning-SFT' isn't based on a loading script and remove `trust_remote_code`.\n",
            "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/19704 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e116cd2c0f664dac82e0d6a07523d2fb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "medical_dataset[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXfWjgutXgqW",
        "outputId": "107132db-1406-4b2a-aeb1-58be49021b06"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Question': 'A 33-year-old woman is brought to the emergency department 15 minutes after being stabbed in the chest with a screwdriver. Given her vital signs of pulse 110/min, respirations 22/min, and blood pressure 90/65 mm Hg, along with the presence of a 5-cm deep stab wound at the upper border of the 8th rib in the left midaxillary line, which anatomical structure in her chest is most likely to be injured?',\n",
              " 'Complex_CoT': \"Okay, let's figure out what's going on here. A woman comes in with a stab wound from a screwdriver. It's in her chest, upper border of the 8th rib, left side, kind of around the midaxillary line. First thought, that's pretty close to where the lung sits, right?\\n\\nLet's talk about location first. This spot is along the left side of her body. Above the 8th rib, like that, is where a lot of important stuff lives, like the bottom part of the left lung, possibly the diaphragm too, especially considering how deep the screwdriver went.\\n\\nThe wound is 5 cm deep. That sounds pretty deep. I mean, it could definitely reach down to the lung tissue or maybe the diaphragm. Given that it's midaxillary, we're in the territory where the lower lobe of the left lung hangs out. It's also possible there's some intersection with where the diaphragm begins, but the lung feels more probable somehow.\\n\\nNow, her vitals are concerning: elevated heart rate and low blood pressure. This is serious. My gut says that this kind of vital sign picture could mean something like pneumothorax or maybe hemothorax. Both can happen if the lung gets punctured, and they can make the blood pressure drop and the heart rate skyrocket since she's obviously distressed.\\n\\nSo, putting it all together, the most obvious culprit is the lower lobe of the left lung. The wound's depth and her condition point that way. And, yeah, this adds up with pneumothorax or maybe blood collecting in the chest‚Äîthe kind of stuff that can really mess with breathing and circulation.\\n\\nAlright, with this in mind, it sure seems like the lung is the most likely thing that got hurt here. Makes sense given the situation, where the wound is, considering her symptoms, and the whole setup.\",\n",
              " 'Response': 'In this scenario, the most likely anatomical structure to be injured is the lower lobe of the left lung. The location of the stab wound‚Äîat the upper border of the 8th rib in the left midaxillary line‚Äîindicates proximity to the lower lobe of the lung. The depth of the wound (5 cm) suggests it is sufficient to reach lung tissue. Her vital signs of elevated heart rate and low blood pressure could signal complications like a pneumothorax or hemothorax, common consequences of lung trauma that would result from a penetrating injury in this area. Given these considerations, the lower lobe of the left lung is the most probable structure injured.'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EOS_TOKEN = tokenizer.eos_token  # Define EOS_TOKEN which tells the model when to stop generating text during training\n",
        "EOS_TOKEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "D_0B7eGsXuJM",
        "outputId": "b6bfb384-e1c7-4de7-f8ca-845b449e3ac7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<ÔΩúend‚ñÅof‚ñÅsentenceÔΩú>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
        "Write a response that appropriately completes the request.\n",
        "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
        "\n",
        "### Instruction:\n",
        "You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning.\n",
        "Please answer the following medical question.\n",
        "\n",
        "### Question:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "\n",
        "{}\n",
        "\n",
        "{}\"\"\""
      ],
      "metadata": {
        "id": "n01Hb9JfX0Nv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_input_data(examples):\n",
        "  inputs = examples[\"Question\"]\n",
        "  cots = examples[\"Complex_CoT\"]\n",
        "  outputs = examples[\"Response\"]\n",
        "\n",
        "  texts = []\n",
        "\n",
        "  for input, cot, output in zip(inputs, cots, outputs):\n",
        "    text = train_prompt_style.format(input, cot, output) + EOS_TOKEN\n",
        "    texts.append(text)\n",
        "\n",
        "  return texts"
      ],
      "metadata": {
        "id": "lerzZwJYX20m"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finetune_dataset = medical_dataset.map(preprocess_input_data, batched = True)\n",
        "# This line is no longer needed as formatting will be handled by SFTTrainer directly."
      ],
      "metadata": {
        "id": "foTGQjm2X6K_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetune_dataset[\"texts\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "Lk61GdS2X6jN",
        "outputId": "21cb2736-f5af-4da1-8285-629cd754b6e0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'finetune_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2786397223.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinetune_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"texts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'finetune_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_lora = FastLanguageModel.get_peft_model(\n",
        "    model = model,\n",
        "    r = 16,\n",
        "    target_modules = [\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\"\n",
        "    ],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 3047,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8M14cdGX780",
        "outputId": "0151e378-5649-4229-cc87-734bea22d4d7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2026.1.4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if hasattr(model, '_unwrapped_old_generate'):\n",
        "    del model._unwrapped_old_generate"
      ],
      "metadata": {
        "id": "TF6yMw26Yma9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model = model_lora,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = medical_dataset, # Use original dataset\n",
        "    # dataset_text_field = \"texts\", # Removed, formatting_func handles it\n",
        "    max_seq_length = max_sequence_length,\n",
        "    dataset_num_proc = 1,\n",
        "    formatting_func = preprocess_input_data, # Explicitly provide formatting function\n",
        "\n",
        "    # Define training args\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 1, # Reduced from 2 to 1\n",
        "        gradient_accumulation_steps = 4,\n",
        "        num_train_epochs = 1,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 60,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps = 10,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "33977379baec4807b9caf39508979a1c",
            "72c34160ae3f460095a21b5f0068e8a3",
            "a3b45ff39d16465b8e88d4259070b518",
            "b4bdb99c498c44e6986f1dade6486216",
            "0cac67badfed4bb6952d3e3fe7e26e82",
            "f2d0ac22a5e145acabb52b657fb6e580",
            "0f45bc0a53714588bf6868e829c68982",
            "033d2fc08cd449219e4fcaad4a5dfd41",
            "91d910431eee441bac359cb550036d52",
            "a3eb7342a87842b385b1e35d78a199f7",
            "a4a69782a79241509ad8563e5816fd8d"
          ]
        },
        "id": "AsLDO9PUY-M6",
        "outputId": "23bedf31-e280-4ce0-a32f-ac55ddf9f446"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=4):   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33977379baec4807b9caf39508979a1c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "2a186190",
        "outputId": "67f48d96-9286-4c81-b5d6-0823af911d80"
      },
      "source": [
        "from google.colab import userdata\n",
        "wnb_token = userdata.get(\"WANDB_API_TOKEN\")\n",
        "# Login to WnB\n",
        "wandb.login(key=wnb_token) # import wandb\n",
        "run = wandb.init(\n",
        "    project='Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset',\n",
        "    job_type=\"training\",\n",
        "    anonymous=\"allow\"\n",
        ")\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "wandb: [wandb.login()] Using explicit session credentials for https://api.wandb.ai.\n",
            "wandb: No netrc file found, creating one.\n",
            "wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "wandb: Currently logged in as: abhar9879 (abhar9879-student) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: WARNING The anonymous setting has no effect and will be removed in a future version.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.24.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260202_100412-p5f4n4mn</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abhar9879-student/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset/runs/p5f4n4mn' target=\"_blank\">wobbly-night-1</a></strong> to <a href='https://wandb.ai/abhar9879-student/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/abhar9879-student/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset' target=\"_blank\">https://wandb.ai/abhar9879-student/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/abhar9879-student/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset/runs/p5f4n4mn' target=\"_blank\">https://wandb.ai/abhar9879-student/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset/runs/p5f4n4mn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: Detected [huggingface_hub.inference, openai] in use.\n",
            "wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
            "wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "id": "53fea773",
        "outputId": "d8e0d815-8d29-4afc-9ccc-297668361977"
      },
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 500 | Num Epochs = 1 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4\n",
            " \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 06:27, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.961300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.487600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.397800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.350600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.389500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.377100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñà‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>7517902833721344.0</td></tr><tr><td>train/epoch</td><td>0.48</td></tr><tr><td>train/global_step</td><td>60</td></tr><tr><td>train/grad_norm</td><td>0.3614</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3771</td></tr><tr><td>train_loss</td><td>1.49397</td></tr><tr><td>train_runtime</td><td>402.7252</td></tr><tr><td>train_samples_per_second</td><td>0.596</td></tr><tr><td>train_steps_per_second</td><td>0.149</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">wobbly-night-1</strong> at: <a href='https://wandb.ai/abhar9879-student/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset/runs/p5f4n4mn' target=\"_blank\">https://wandb.ai/abhar9879-student/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset/runs/p5f4n4mn</a><br> View project at: <a href='https://wandb.ai/abhar9879-student/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset' target=\"_blank\">https://wandb.ai/abhar9879-student/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260202_100412-p5f4n4mn/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "sMScsHmmZRSc"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing\n",
        "              but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings,\n",
        "              what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\"\"\n",
        "\n",
        "FastLanguageModel.for_inference(model_lora)\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate a response\n",
        "outputs = model_lora.generate (\n",
        "    input_ids = inputs.input_ids,\n",
        "    attention_mask = inputs.attention_mask,\n",
        "    max_new_tokens = 1200,\n",
        "    use_cache = True\n",
        ")\n",
        "\n",
        "# Decode the response tokens back to text\n",
        "response = tokenizer.batch_decode(outputs)\n",
        "\n",
        "print(response)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K0qzAPpvGyl",
        "outputId": "77d28f46-afda-42cb-c7fb-bab6b1ae75b3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"<ÔΩúbegin‚ñÅof‚ñÅsentenceÔΩú>\\nBelow is a task description along with additional context provided in the input section. Your goal is to provide a well-reasoned response that effectively addresses the request.\\n\\nBefore crafting your answer, take a moment to carefully analyze the question. Develop a clear, step-by-step thought process to ensure your response is both logical and accurate.\\n\\n### Task:\\nYou are a medical expert specializing in clinical reasoning, diagnostics, and treatment planning. Answer the medical question below using your advanced knowledge.\\n\\n### Query:\\nA 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing\\n              but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings,\\n              what would cystometry most likely reveal about her residual volume and detrusor contractions?\\n\\n### Answer:\\n\\nAlright, let's think about this. This woman is 61 and has been dealing with involuntary urine loss for a long time, especially when she coughs or sneezes. That's a classic sign of urinary incontinence, probably due to an overactive bladder. \\n\\nNow, she's done a Q-tip test, which is often used to check for urethral obstruction. If the Q-tip stays at 30 cm or higher, that usually means there's some obstruction. But I remember that it doesn't always directly tell us about the volume or how the bladder responds.\\n\\nNext, let's think about cystometry. This test is all about how the bladder behaves. If her bladder is overactive, it means it's more likely to contract when there's any volume. So, if she's coughing or sneezing, her bladder might be contracting involuntarily, causing the urge to pee.\\n\\nNow, if we look at the residual volume in her bladder, it's usually around 200-300 ml. But if her bladder is overactive, it can contract even when it's not full, leading to more frequent urination. \\n\\nDetrusor contractions themselves are a key part of this. The detrusor muscle, which lines the bladder, contracts to push out urine. If the bladder is overactive, these contractions happen more often, especially when we're doing activities that might put pressure on the bladder, like coughing.\\n\\nPutting it all together, the cystometry would likely show her bladder is overactive. The detrusor contractions are happening more than usual, and there's definitely some residual volume in the bladder. \\n\\nSo, it seems like the cystometry would confirm that her bladder is overactive, and she's dealing with some residual volume in the bladder due to these involuntary contractions. That makes sense with everything we know about her symptoms and the tests she's done.\\n\\nBased on the findings from the gynecological exam and Q-tip test, cystometry would most likely reveal that her bladder is overactive, characterized by an involuntary detrusor contraction, and there would be residual volume in the bladder.<ÔΩúend‚ñÅof‚ñÅsentenceÔΩú>\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(response[0].split(\"### Answer:\")[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcI98pLy3Od8",
        "outputId": "10aa1cb8-9a2d-448f-b498-007a12ca41a8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Alright, let's think about this. This woman is 61 and has been dealing with involuntary urine loss for a long time, especially when she coughs or sneezes. That's a classic sign of urinary incontinence, probably due to an overactive bladder. \n",
            "\n",
            "Now, she's done a Q-tip test, which is often used to check for urethral obstruction. If the Q-tip stays at 30 cm or higher, that usually means there's some obstruction. But I remember that it doesn't always directly tell us about the volume or how the bladder responds.\n",
            "\n",
            "Next, let's think about cystometry. This test is all about how the bladder behaves. If her bladder is overactive, it means it's more likely to contract when there's any volume. So, if she's coughing or sneezing, her bladder might be contracting involuntarily, causing the urge to pee.\n",
            "\n",
            "Now, if we look at the residual volume in her bladder, it's usually around 200-300 ml. But if her bladder is overactive, it can contract even when it's not full, leading to more frequent urination. \n",
            "\n",
            "Detrusor contractions themselves are a key part of this. The detrusor muscle, which lines the bladder, contracts to push out urine. If the bladder is overactive, these contractions happen more often, especially when we're doing activities that might put pressure on the bladder, like coughing.\n",
            "\n",
            "Putting it all together, the cystometry would likely show her bladder is overactive. The detrusor contractions are happening more than usual, and there's definitely some residual volume in the bladder. \n",
            "\n",
            "So, it seems like the cystometry would confirm that her bladder is overactive, and she's dealing with some residual volume in the bladder due to these involuntary contractions. That makes sense with everything we know about her symptoms and the tests she's done.\n",
            "\n",
            "Based on the findings from the gynecological exam and Q-tip test, cystometry would most likely reveal that her bladder is overactive, characterized by an involuntary detrusor contraction, and there would be residual volume in the bladder.<ÔΩúend‚ñÅof‚ñÅsentenceÔΩú>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "question = \"\"\"A 59-year-old man presents with a fever, chills, night sweats, and generalized fatigue,\n",
        "              and is found to have a 12 mm vegetation on the aortic valve. Blood cultures indicate gram-positive, catalase-negative,\n",
        "              gamma-hemolytic cocci in chains that do not grow in a 6.5% NaCl medium.\n",
        "              What is the most likely predisposing factor for this patient's condition?\"\"\"\n",
        "\n",
        "FastLanguageModel.for_inference(model_lora)\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate a response\n",
        "outputs = model_lora.generate (\n",
        "    input_ids = inputs.input_ids,\n",
        "    attention_mask = inputs.attention_mask,\n",
        "    max_new_tokens = 1200,\n",
        "    use_cache = True\n",
        ")\n",
        "\n",
        "# Decode the response tokens back to text\n",
        "response = tokenizer.batch_decode(outputs)\n",
        "\n",
        "print(response[0].split(\"### Answer:\")[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2OMyMv23li4",
        "outputId": "8c6613cd-cc83-4adf-94c1-cbf723d7ea06"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Okay, let's see. We have a 59-year-old guy with a fever, chills, night sweats, and just feels really tired all the time. That's classic for an infection, right? So, this guy definitely has an infection going on. Now, let's look at the details.\n",
            "\n",
            "He's got this vegetation on his aortic valve, measuring 12 mm. That's pretty big. And the blood cultures tell us it's gram-positive, catalase-negative, and they're these gamma-hemolytic cocci that show up in chains. Hmm, this sounds familiar. I'm thinking it's probably something like endocarditis, given the vegetation and the kind of bacteria we're seeing.\n",
            "\n",
            "Wait, but let's think about the bacteria. Gram-positive, catalase-negative, and gamma-hemolytic cocci in chains. That's not a typical scenario for most common infections. Oh! It sounds like it's a type of viridans group of bacteria. I remember viridans are gram-positive, catalase-negative, and they don't grow well in high salt environments, like the 6.5% NaCl they mentioned. Yeah, that fits perfectly.\n",
            "\n",
            "So, what causes viridans? Well, these bacteria are usually harmless, but when they end up in the heart, they can cause endocarditis. They don't have the typical pathogenicity of other bacteria like staph or strepto. So, why are they here? It's probably due to some underlying issue that allows them to get into the bloodstream and then the heart.\n",
            "\n",
            "Now, what could lead to this? There are a few possibilities. There's the possibility of having heart surgery or a catheter procedure, which could introduce these bacteria. Or there's something like an immune disorder or maybe even some kind of prosthetic valve that's been put in. Oh, and there's also the possibility of having some kind of immune suppression going on.\n",
            "\n",
            "Wait, let's think about immune suppression. When people have weakened immune systems, they're more likely to get infections because the body isn't able to fight off these bacteria as well. It's like when the immune system isn't functioning properly, it's easier for the bacteria to get a hold.\n",
            "\n",
            "Now, what's common in this situation? The patient is 59, which is pretty advanced, but it's not necessarily the age that's the problem. It's more about what's going on in the body that's making this infection possible.\n",
            "\n",
            "Alright, putting this all together, the most likely thing that's allowing this viridans infection to take place is probably something related to immune suppression. Maybe the patient has an autoimmune condition or is taking some kind of immunosuppressive medication. That could explain why the bacteria are getting a foothold in the body.\n",
            "\n",
            "So, yeah, I think the most probable factor here is immune suppression. It's a common scenario where these bacteria can thrive in the body, leading to infections like endocarditis.\n",
            "\n",
            "The most likely predisposing factor for this patient's condition is immune suppression. This could be due to an autoimmune condition, organ transplant, or immunosuppressive medications, all of which weaken the immune system, making it easier for the viridans bacteria to establish an infection.<ÔΩúend‚ñÅof‚ñÅsentenceÔΩú>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FcKiqt7h3ooE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}